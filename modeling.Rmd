# Modeling in R

*under construction*

The purpose of a statistical model is to help understand what variables might best predict a phenomenon of interest, which ones have more or less influence, define a predictive equation with coefficients for each of the variables, and then apply that equation to predict values using the same input variables for other areas. This process requires samples of the predictor and response variables in question.  

## Some common statistical models

There are many types of statistical models. Variables may be nominal (categorical) or interval/ratio data.  You may be interested in predicting a continuous interval/ratio variable from other continuous variables, or predicting the probability of an occurrence (e.g. of a species), or maybe the count of something (also maybe a species). You may be needing to classify your phenomena based on continuous variables.

- `lm(y ~ x)`	linear regression
- `lm(y ~ x1 + x2 + x3)`	multiple regression
- `glm(y ~ x, family = poisson)`	generalized linear model, poisson distribution; 
see ?family to see those supported, including binomial, gaussian, poisson, etc.
- `aov(y ~ x)`	analysis of variance (same as lm except in the summary)
- gam(y ~ x)	generalized additive models
- tree(y ~ x)  or  rpart(y ~ x)	regression/classification trees    

```{r message=F, warning=F}
model1 <- lm(TEMPERATURE ~ ELEVATION, data = sierraFeb)
summary(model1)
```

Probably the most important statistic is the p value for the predictor variable ELEVATION, which in this case is very small <2e-16.

```{r echo=F, message=F}
library(iGIScData)
library(tidyverse)
sierraFeb <- sierraFeb %>%
  filter(!is.na(TEMPERATURE))
model1 = lm(TEMPERATURE ~ ELEVATION, data = sierraFeb)
cc = model1$coefficients
sierraFeb$resid = resid(model1)
sierraFeb$predict = predict(model1) 
eqn = paste("temperature =", paste(round(cc[1],2), paste(round(cc[-1], digits=3), sep="*", collapse=" + ", paste("elevation")), sep=" + "), "+ e")
ggplot(sierraFeb, aes(x=ELEVATION, y=TEMPERATURE)) + 
  geom_smooth(method="lm", se=FALSE, color="lightgrey") +
  geom_segment(aes(xend=ELEVATION, yend=predict), alpha=.2) +
  geom_point(aes(color=resid)) +
  scale_color_gradient2(low="blue", mid="ivory2", high="red") +
  guides(color=FALSE) +
  theme_bw() +
  ggtitle(paste("Residuals (e) from model: ",eqn))
model1
```

**Making Predictions**

```{r message=F, warning=F}
eqn
a <- model1$coefficients[1]
b <- model1$coefficients[2]
elevations <- c(500, 1000, 1500, 2000)
elevations
tempEstimate <- a + b * elevations
tempEstimate
```

### Analysis of Covariance

Same purpose as Analysis of Variance, but also takes into account the influence of other variables called covariates. In a way, combines a linear model with an analysis of variance.

*"Are water samples from streams draining sandstone, limestone,  and shale different based on pH, while taking into account elevation?"*

Response variable is modeled from the factor (ANOVA) plus the covariate (regression)

- ANOVA:   pH ~ rocktype
- Regression:  pH ~ elevation
- ANCOVA:  pH ~ rocktype + elevation
   - Yet shouldn't involve interaction between rocktype and elevation
   
**Example:  stream types distinguished by discharge and slope**

Three common river types are meandering, braided and anastomosed. For each, their slope
varies by bankfull discharge in a relationship that looks something like:

<img src="img/SbyQ_rivers.png">

<img src="img/braided.png" alt="braided">
<img src="img/meandering.png" alt="meandering">
<img src="img/anastomosed.png" alt="anastomosed">

No interaction between covariate and factor 

- No relationship between discharge and channel type.  
- Another interpretation:  the slope of the relationship between the covariate and response variable is about the same for each group; only the intercept differs.  Assumes parallel slopes.

`log10(S) ~ strtype * log10(Q)`   … interaction between covariate and factor

`log10(S) ~ strtype + log10(Q)`   … no interaction, parallel slopes

If models are not significantly different, remove interaction term due to parsimony, and satisfies this ANCOVA requirement.


```{r message=F, warning=F}
library(tidyverse)
csvPath <- system.file("extdata","streams.csv", package="iGIScData")
streams <- read_csv(csvPath)
streams$strtype <- factor(streams$type, labels=c("Anastomosing","Braided","Meandering"))
summary(streams)
ggplot(streams, aes(Q, S, color=strtype)) +
  geom_point()
library(scales) # needed for the trans_format function below
ggplot(streams, aes(Q, S, color=strtype)) +
  geom_point() + geom_smooth(method="lm", se = FALSE) + 
  scale_x_continuous(trans=log10_trans(),
                     labels = trans_format("log10", math_format(10^.x))) +
  scale_y_continuous(trans=log10_trans(),
                     labels = trans_format("log10", math_format(10^.x)))
ancova = lm(log10(S)~strtype*log10(Q), data=streams)
summary(ancova)
anova(ancova)

# Now an additive model, which does not have that interaction
ancova2 = lm(log10(S)~strtype+log10(Q), data=streams)
anova(ancova2)
anova(ancova,ancova2)   
   # not significantly different, so model simplification is justified

# Now we remove the strtype term
ancova3 = update(ancova2, ~ . - strtype)  
anova(ancova2,ancova3)  
   # Goes too far.  Removing the strtype creates a significantly different model

step(ancova)

```

**Part of general linear model (lm)**

ANOVA & ANCOVA are applications of a general linear model.

- Uses lm in R
- Response variable is continuous, assumed normally distributed

*Not the same as Generalized Linear Model (GLM)*

- *With GLM, response variable may be from count data (e.g. Poisson), probabilities of occurrence (logistic regression) or other non-normal distributions.*

`mymodel = lm(log10(s) ~ strtype + log10(Q))`

- The linear model, with categorical explanatory variable  + covariate

`anova(mymodel)`

- Displays the Analysis of Variance table from the linear model

## Generalized Linear Model (GLM)

The glm in R allows you to work with various types of data using various distributions, described as families such as:

- gaussian : normal distribution – what is used with lm
- binomial : logit – used with probabilities.
   - Used for *logistic regression*
- poisson : for counts.  Commonly used for species counts.
- see help(glm) for other examples

Great explanation of poisson distribution using meteor showers at:

<a href="https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459">https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459</a>

## Models Employing Machine Learning

Models using machine learning algorithms are commonly used in data science, fitting with its general exploratory and data-mining approach. There are many machine learning algorithms, and many resources for learning more about them, but they all share a basically black-box approach where a collection of variables are explored for patterns in input variables that help to explain a response variable. The latter is similar to more conventional statistical modeling describe above, with the difference being the machine learning approach -- think of robots going through your data looking for connections.

We'll explore a few machine learning methods (such as neural networks, random forests, and support vector machines) in a later chapter when we attempt to use them to classify satellite imagery, an important environmental application. As this application is in the spatial domain, we'll first look into spatial statistical methods. 
